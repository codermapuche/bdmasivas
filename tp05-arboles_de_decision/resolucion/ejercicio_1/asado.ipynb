{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Universidad Nacional de Lujan - Bases de Datos Masivas (11088) - Cavasin Nicolas #143501\n",
    "# TP05-01 - Árboles de decisión\n",
    "\n",
    "### Ejercicio 1:\n",
    "A  partir  del  dataset  presentado  a  continuación,  y  teniendo  en  cuenta  las fórmulas de entropía y ganancia de información, calcule y diagrame el árbol de decisión que le permita decidir si comer asado o no en función del clima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!conda update --update-all -y\n",
    "#!conda update -y conda\n",
    "#!conda install -y pandas\n",
    "#!conda install -y scikit-learn\n",
    "#!conda install -y graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Archivo encontrado.\nEliminando db-asado.xls...\n\nIniciando descarga...\n\n\n--2020-11-11 17:10:59--  https://raw.githubusercontent.com/bdm-unlu/2020/master/TPs/TP05/TP0501/db-asado.xls\nLoaded CA certificate &#39;/etc/ssl/certs/ca-certificates.crt&#39;\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.216.133\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.216.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 29184 (28K) [application/octet-stream]\nSaving to: &#39;db-asado.xls&#39;\n\ndb-asado.xls        100%[===================&gt;]  28.50K  --.-KB/s    in 0.02s   \n\n2020-11-11 17:10:59 (1.75 MB/s) - &#39;db-asado.xls&#39; saved [29184/29184]\n\n"
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "if os.path.exists(\"db-asado.xls\"):\n",
    "    !echo Archivo encontrado.\n",
    "    !echo Eliminando db-asado.xls...\n",
    "    !rm db-asado.xls\n",
    "\n",
    "# Descargo el archivo con el cual se va a trabajar\n",
    "!echo \n",
    "!echo Iniciando descarga...\n",
    "!echo\n",
    "!echo\n",
    "!wget https://raw.githubusercontent.com/bdm-unlu/2020/master/TPs/TP05/TP0501/db-asado.xls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  PRONÓSTICO TEMPERATURA HUMEDAD  VIENTO ASADO\n0    soleado       calor    alta    leve    no\n1    soleado       calor    alta  fuerte    no\n2    nublado       calor    alta    leve    si\n3   lluvioso    templado    alta    leve    si\n4   lluvioso        frío  normal    leve    si",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PRONÓSTICO</th>\n      <th>TEMPERATURA</th>\n      <th>HUMEDAD</th>\n      <th>VIENTO</th>\n      <th>ASADO</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>soleado</td>\n      <td>calor</td>\n      <td>alta</td>\n      <td>leve</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>soleado</td>\n      <td>calor</td>\n      <td>alta</td>\n      <td>fuerte</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>nublado</td>\n      <td>calor</td>\n      <td>alta</td>\n      <td>leve</td>\n      <td>si</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>lluvioso</td>\n      <td>templado</td>\n      <td>alta</td>\n      <td>leve</td>\n      <td>si</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>lluvioso</td>\n      <td>frío</td>\n      <td>normal</td>\n      <td>leve</td>\n      <td>si</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Importo pandas para leer el archivo\n",
    "import pandas as pd\n",
    "\n",
    "# Leo el archivo\n",
    "datos = pd.read_excel(\"db-asado.xls\")\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total de tuplas = 14.\nTotal de columnas = 5.\n"
    }
   ],
   "source": [
    "# Muestro su distribución de tuplas y columnas\n",
    "print(f\"Total de tuplas = {datos.shape[0]}.\")\n",
    "print(f\"Total de columnas = {datos.shape[1]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, los datos almacenados son del tipo *String* y eso es un problema para la generación del árbol de clasificación. Por lo tanto, se deben transformar a valores numéricos y categóricos (discretos).\n",
    "\n",
    "Durante la transformación, por cada **columna original** se *crearán* tantas **nuevas columnas** como **diferentes valores** posea cada columna y se representará su valor al estilo bitmap según la nueva columna a la que pertenezca, dejando las otras en 0. Este método es conocido como **one-hot-encoding**.\n",
    "\n",
    "Para ser más claro, se ejemplifica a continuación con una de las 4 columnas de features (pero se aplica a todas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importo el encoder necesario para transformar\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "\n",
    "# Guardo el target\n",
    "target = datos.pop(\"ASADO\")\n",
    "\n",
    "# Guardo las features\n",
    "features = datos.copy()\n",
    "\n",
    "# Instancio el encoder\n",
    "ohe = OneHotEncoder(sparse=False, handle_unknown='error')\n",
    "\n",
    "# Le enseño a codificar las features y las guardo en un dataframe\n",
    "trans_features = pd.DataFrame(ohe.fit_transform(features))\n",
    "trans_features.head()\n",
    "# Guardo los nombres\n",
    "trans_feature_names = ohe.get_feature_names()"
   ]
  },
  {
   "source": [
    "asdasd"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "&#39;asado&#39;"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# Importo la libreria para construir el arbol\n",
    "from sklearn import tree\n",
    "\n",
    "# Importo libreria para graficar \n",
    "import graphviz\n",
    "\n",
    "# Importo un clasificador para separar set de entrenamiento y set de testeo\n",
    "from sklearn.model_selection import train_test_split as splitter\n",
    "\n",
    "# Separo en 80:20 entrenamiento y testeo\n",
    "train_features, test_features, train_target, test_target = splitter(trans_features, target, random_state=0, test_size=0.3)\n",
    "\n",
    "# Instancio el arbol para que sea clasificador y que lo haga por entropia\n",
    "t = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "\n",
    "# Entreno el arbol\n",
    "t.fit(train_features, train_target)\n",
    "\n",
    "# Realizo las predicciones en función del árbol generado\n",
    "predictions = t.predict(test_features)\n",
    "\n",
    "# Exporto el arbol en formato DOT (ver referencias abajo) para usar con graphviz\n",
    "dot_file = tree.export_graphviz(t \n",
    "                    , out_file=None\n",
    "                    , feature_names=trans_feature_names\n",
    "                    , class_names=target.name\n",
    "                    , filled=True\n",
    "                    , rounded=True\n",
    "                    , special_characters=True\n",
    "                    , precision=4)\n",
    "\n",
    "\n",
    "# Capturo el source\n",
    "graph = graphviz.Source(dot_file)\n",
    "\n",
    "# Le digo que lo almacene como .png\n",
    "graph.format = \"png\"\n",
    "graph.save('asado')\n",
    "\n"
   ]
  },
  {
   "source": [
    "![Arbol](asado.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [14, 5]",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m&lt;ipython-input-9-faf07e05e873&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Vamos a testear el modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----&gt; 4\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf&quot;Accuracy: {acc}&quot;\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---&gt; 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--&gt; 187\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m&#39;multilabel&#39;\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     &quot;&quot;&quot;\n\u001b[0;32m---&gt; 81\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&gt;\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--&gt; 255\u001b[0;31m         raise ValueError(&quot;Found input variables with inconsistent numbers of&quot;\n\u001b[0m\u001b[1;32m    256\u001b[0m                          &quot; samples: %r&quot; % [int(l) for l in lengths])\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [14, 5]"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics \n",
    "\n",
    "# Vamos a testear el modelo\n",
    "acc = metrics.accuracy_score(target, predictions)\n",
    "print(f\"Accuracy: {acc}\")\n",
    "\n",
    "# Vemos un reporte de clasificación de varias métricas\n",
    "print(metrics.classification_report(target, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referencias:\n",
    "\n",
    "- La [indexación][0] de data frames en Pandas. \n",
    "- Como funciona el [preprocesamiento][1] en Scikit-Learn.\n",
    "- [Workflow][2] de transformaciones por el método 'one-hot-encoding'.\n",
    "- Formato [DOT][3].\n",
    "\n",
    "[0]:https://pandas.pydata.org/docs/user_guide/indexing.html#indexing\n",
    "[1]:https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "[2]:https://medium.com/dunder-data/from-pandas-to-scikit-learn-a-new-exciting-workflow-e88e2271ef62 \n",
    "[3]:https://graphviz.org/doc/info/lang.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}