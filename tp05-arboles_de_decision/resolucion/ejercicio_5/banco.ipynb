{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.6 64-bit",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### Universidad Nacional de Lujan - Bases de Datos Masivas (11088) - Cavasin Nicolas #143501\n",
    "# TP05-01 - Árboles de decisión\n",
    "\n",
    "### Ejercicio 5:\n",
    "Un Banco de Portugal realizó una campaña de marketing en busca de clientes de plazos fijos basada en llamados telefónicos. Se provee el dataset real *(bank-full.csv)* con más 45000 instancias y el detalle *(bank-names.txt)* de los datos registrados de cada una de las personas contactadas por la entidad bancaria:\n",
    "- Realice las tareas necesarias para poder procesar el dataset en Scikit-Learn.\n",
    "- Luego, genere el árbol de decisión, y optimice los resultados, con el objetivo de explicar cuáles son las características más importantes que permiten identificar a una persona que accederá o no al plazo fijo. Documente los resultados."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "!rm bank-full.csv\n",
    "!rm bank-names.txt\n",
    "!wget https://raw.githubusercontent.com/bdm-unlu/2020/master/TPs/TP05/TP0501/bank-full.csv\n",
    "!wget https://raw.githubusercontent.com/bdm-unlu/2020/master/TPs/TP05/TP0501/bank-names.txt"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "--2020-11-11 18:03:07--  https://raw.githubusercontent.com/bdm-unlu/2020/master/TPs/TP05/TP0501/bank-full.csv\nLoaded CA certificate &#39;/etc/ssl/certs/ca-certificates.crt&#39;\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.216.133\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.216.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 4610348 (4.4M) [text/plain]\nSaving to: &#39;bank-full.csv&#39;\n\nbank-full.csv       100%[===================&gt;]   4.40M  2.48MB/s    in 1.8s    \n\n2020-11-11 18:03:09 (2.48 MB/s) - &#39;bank-full.csv&#39; saved [4610348/4610348]\n\n--2020-11-11 18:03:10--  https://raw.githubusercontent.com/bdm-unlu/2020/master/TPs/TP05/TP0501/bank-names.txt\nLoaded CA certificate &#39;/etc/ssl/certs/ca-certificates.crt&#39;\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.216.133\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.216.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3794 (3.7K) [text/plain]\nSaving to: &#39;bank-names.txt&#39;\n\nbank-names.txt      100%[===================&gt;]   3.71K  --.-KB/s    in 0.001s  \n\n2020-11-11 18:03:10 (6.68 MB/s) - &#39;bank-names.txt&#39; saved [3794/3794]\n\n"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\nCantidad de tuplas: 45211\nCantidad de columnas: 1\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  age;&quot;job&quot;;&quot;marital&quot;;&quot;education&quot;;&quot;default&quot;;&quot;balance&quot;;&quot;housing&quot;;&quot;loan&quot;;&quot;contact&quot;;&quot;day&quot;;&quot;month&quot;;&quot;duration&quot;;&quot;campaign&quot;;&quot;pdays&quot;;&quot;previous&quot;;&quot;poutcome&quot;;&quot;y&quot;\n0  58;&quot;management&quot;;&quot;married&quot;;&quot;tertiary&quot;;&quot;no&quot;;2143...                                                                                                  \n1  44;&quot;technician&quot;;&quot;single&quot;;&quot;secondary&quot;;&quot;no&quot;;29;&quot;...                                                                                                  \n2  33;&quot;entrepreneur&quot;;&quot;married&quot;;&quot;secondary&quot;;&quot;no&quot;;2...                                                                                                  \n3  47;&quot;blue-collar&quot;;&quot;married&quot;;&quot;unknown&quot;;&quot;no&quot;;1506...                                                                                                  \n4  33;&quot;unknown&quot;;&quot;single&quot;;&quot;unknown&quot;;&quot;no&quot;;1;&quot;no&quot;;&quot;n...                                                                                                  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age;\"job\";\"marital\";\"education\";\"default\";\"balance\";\"housing\";\"loan\";\"contact\";\"day\";\"month\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"y\"</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>58;\"management\";\"married\";\"tertiary\";\"no\";2143...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>44;\"technician\";\"single\";\"secondary\";\"no\";29;\"...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>33;\"entrepreneur\";\"married\";\"secondary\";\"no\";2...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>47;\"blue-collar\";\"married\";\"unknown\";\"no\";1506...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>33;\"unknown\";\"single\";\"unknown\";\"no\";1;\"no\";\"n...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "banco = pd.read_csv(\"bank-full.csv\")\n",
    "\n",
    "print(type(banco))\n",
    "print(f'Cantidad de tuplas: {banco.shape[0]}')\n",
    "print(f'Cantidad de columnas: {banco.shape[1]}')\n",
    "\n",
    "banco.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Citation Request:\n  This dataset is public available for research. The details are described in [Moro et al., 2011]. \n  Please include this citation if you plan to use this database:\n\n  [Moro et al., 2011] S. Moro, R. Laureano and P. Cortez. Using Data Mining for Bank Direct Marketing: An Application of the CRISP-DM Methodology. \n  In P. Novais et al. (Eds.), Proceedings of the European Simulation and Modelling Conference - ESM&#39;2011, pp. 117-121, Guimarães, Portugal, October, 2011. EUROSIS.\n\n  Available at: [pdf] http://hdl.handle.net/1822/14838\n                [bib] http://www3.dsi.uminho.pt/pcortez/bib/2011-esm-1.txt\n\n1. Title: Bank Marketing\n\n2. Sources\n   Created by: Paulo Cortez (Univ. Minho) and Sérgio Moro (ISCTE-IUL) @ 2012\n   \n3. Past Usage:\n\n  The full dataset was described and analyzed in:\n\n  S. Moro, R. Laureano and P. Cortez. Using Data Mining for Bank Direct Marketing: An Application of the CRISP-DM Methodology. \n  In P. Novais et al. (Eds.), Proceedings of the European Simulation and Modelling Conference - ESM&#39;2011, pp. 117-121, Guimarães, \n  Portugal, October, 2011. EUROSIS.\n\n4. Relevant Information:\n\n   The data is related with direct marketing campaigns of a Portuguese banking institution. \n   The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, \n   in order to access if the product (bank term deposit) would be (or not) subscribed. \n\n   There are two datasets: \n      1) bank-full.csv with all examples, ordered by date (from May 2008 to November 2010).\n      2) bank.csv with 10% of the examples (4521), randomly selected from bank-full.csv.\n   The smallest dataset is provided to test more computationally demanding machine learning algorithms (e.g. SVM).\n\n   The classification goal is to predict if the client will subscribe a term deposit (variable y).\n\n5. Number of Instances: 45211 for bank-full.csv (4521 for bank.csv)\n\n6. Number of Attributes: 16 + output attribute.\n\n7. Attribute information:\n\n   For more information, read [Moro et al., 2011].\n\n   Input variables:\n   # bank client data:\n   1 - age (numeric)\n   2 - job : type of job (categorical: &quot;admin.&quot;,&quot;unknown&quot;,&quot;unemployed&quot;,&quot;management&quot;,&quot;housemaid&quot;,&quot;entrepreneur&quot;,&quot;student&quot;,\n                                       &quot;blue-collar&quot;,&quot;self-employed&quot;,&quot;retired&quot;,&quot;technician&quot;,&quot;services&quot;) \n   3 - marital : marital status (categorical: &quot;married&quot;,&quot;divorced&quot;,&quot;single&quot;; note: &quot;divorced&quot; means divorced or widowed)\n   4 - education (categorical: &quot;unknown&quot;,&quot;secondary&quot;,&quot;primary&quot;,&quot;tertiary&quot;)\n   5 - default: has credit in default? (binary: &quot;yes&quot;,&quot;no&quot;)\n   6 - balance: average yearly balance, in euros (numeric) \n   7 - housing: has housing loan? (binary: &quot;yes&quot;,&quot;no&quot;)\n   8 - loan: has personal loan? (binary: &quot;yes&quot;,&quot;no&quot;)\n   # related with the last contact of the current campaign:\n   9 - contact: contact communication type (categorical: &quot;unknown&quot;,&quot;telephone&quot;,&quot;cellular&quot;) \n  10 - day: last contact day of the month (numeric)\n  11 - month: last contact month of year (categorical: &quot;jan&quot;, &quot;feb&quot;, &quot;mar&quot;, ..., &quot;nov&quot;, &quot;dec&quot;)\n  12 - duration: last contact duration, in seconds (numeric)\n   # other attributes:\n  13 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n  14 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client was not previously contacted)\n  15 - previous: number of contacts performed before this campaign and for this client (numeric)\n  16 - poutcome: outcome of the previous marketing campaign (categorical: &quot;unknown&quot;,&quot;other&quot;,&quot;failure&quot;,&quot;success&quot;)\n\n  Output variable (desired target):\n  17 - y - has the client subscribed a term deposit? (binary: &quot;yes&quot;,&quot;no&quot;)\n\n8. Missing Attribute Values: None\n\n"
    }
   ],
   "source": [
    "# Leo el archivo txt\n",
    "with open('bank-names.txt') as metadata:\n",
    "    print(metadata.read())"
   ]
  },
  {
   "source": [
    "Se puede observar que el dataset se encuentra almacenado únicamente en el archivo *bank-full.csv* mientras que *bank-names.txt* funciona como una pseudo-metadata que describe: quiénes son sus creadores, políticas de uso, con qué fin se utilizó, qué es lo que representa cada columna e indica que **no posee datos faltantes**.\n",
    "\n",
    "\n",
    "Al cargar el dataset en memoria usando un *DataFrame*, presenta un formato extraño que posee una única columna en vez de 17 tal como explica el archivo *bank-names.txt*. Lo que hay que modificar es la manera en que se intenta leer a definiendo el parámetro ``sep=\";\"``. \n",
    "\n",
    "A continuación se repite la lectura pero esta vez de manera correcta:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\nCantidad de tuplas: 45211\nCantidad de columnas: 17\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   age           job  marital  education default  balance housing loan  \\\n0   58    management  married   tertiary      no     2143     yes   no   \n1   44    technician   single  secondary      no       29     yes   no   \n2   33  entrepreneur  married  secondary      no        2     yes  yes   \n3   47   blue-collar  married    unknown      no     1506     yes   no   \n4   33       unknown   single    unknown      no        1      no   no   \n\n   contact  day month  duration  campaign  pdays  previous poutcome   y  \n0  unknown    5   may       261         1     -1         0  unknown  no  \n1  unknown    5   may       151         1     -1         0  unknown  no  \n2  unknown    5   may        76         1     -1         0  unknown  no  \n3  unknown    5   may        92         1     -1         0  unknown  no  \n4  unknown    5   may       198         1     -1         0  unknown  no  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>job</th>\n      <th>marital</th>\n      <th>education</th>\n      <th>default</th>\n      <th>balance</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>contact</th>\n      <th>day</th>\n      <th>month</th>\n      <th>duration</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>previous</th>\n      <th>poutcome</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>58</td>\n      <td>management</td>\n      <td>married</td>\n      <td>tertiary</td>\n      <td>no</td>\n      <td>2143</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>unknown</td>\n      <td>5</td>\n      <td>may</td>\n      <td>261</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>44</td>\n      <td>technician</td>\n      <td>single</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>29</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>unknown</td>\n      <td>5</td>\n      <td>may</td>\n      <td>151</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>33</td>\n      <td>entrepreneur</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>2</td>\n      <td>yes</td>\n      <td>yes</td>\n      <td>unknown</td>\n      <td>5</td>\n      <td>may</td>\n      <td>76</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>47</td>\n      <td>blue-collar</td>\n      <td>married</td>\n      <td>unknown</td>\n      <td>no</td>\n      <td>1506</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>unknown</td>\n      <td>5</td>\n      <td>may</td>\n      <td>92</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>33</td>\n      <td>unknown</td>\n      <td>single</td>\n      <td>unknown</td>\n      <td>no</td>\n      <td>1</td>\n      <td>no</td>\n      <td>no</td>\n      <td>unknown</td>\n      <td>5</td>\n      <td>may</td>\n      <td>198</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>no</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Cambio el tipo de separador con el que se interpreta el archivo\n",
    "banco = pd.read_csv(\"bank-full.csv\", sep=\";\")\n",
    "\n",
    "print(type(banco))\n",
    "print(f'Cantidad de tuplas: {banco.shape[0]}')\n",
    "print(f'Cantidad de columnas: {banco.shape[1]}')\n",
    "\n",
    "banco.head()"
   ]
  },
  {
   "source": [
    "Se puede observar que todas las columnas deben ser transformadas para poder ser utilizadas en la creación del árbol de clasificación. Serán separadas las numéricas de las de texto y se hará uso de un *Pipeline* combinado con el método *ColumnTransformer* para simplificar y facilitar el procesamiento (ver referencias al final)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Features numericas a transformar: [&#39;age&#39;, &#39;balance&#39;, &#39;day&#39;, &#39;duration&#39;, &#39;campaign&#39;, &#39;pdays&#39;, &#39;previous&#39;]\nFeatures de texto a transformar: [&#39;job&#39;, &#39;marital&#39;, &#39;education&#39;, &#39;default&#39;, &#39;housing&#39;, &#39;loan&#39;, &#39;contact&#39;, &#39;month&#39;, &#39;poutcome&#39;, &#39;y&#39;]\n"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Defino el target\n",
    "target_name = 'y'\n",
    "#target = banco.pop(target_name)\n",
    "\n",
    "# Defino los nombres de las features\n",
    "feature_names = banco.columns\n",
    "\n",
    "# Inicio listas de cada tipo de feature\n",
    "columnas_numericas = []\n",
    "columnas_texto = []\n",
    "\n",
    "# Separo columnas numericas de columnas de texto\n",
    "for col in banco.columns:\n",
    "    if banco[col].dtype == 'int64' or banco[col].dtype == 'float':\n",
    "        columnas_numericas.append(col)\n",
    "    else:\n",
    "        columnas_texto.append(col)\n",
    "\n",
    "# Muestro cada una\n",
    "print(f'Features numericas a transformar: {columnas_numericas}')\n",
    "\n",
    "print(f'Features de texto a transformar: {columnas_texto}')\n",
    "\n",
    "banco_numericas = banco[columnas_numericas]\n",
    "banco_texto = banco[columnas_texto]"
   ]
  },
  {
   "source": [
    "Se eliminó el target (columna '*y*') del dataframe original y a partir de este se han creado dos nuevos dataframes con el fin de poder trabajar con ellos de manera independiente:\n",
    "- *banco_numericas* contiene todas las columnas numericas del dataset.\n",
    "- *banco_texto* contiene todas las columnas de texto.\n",
    "\n",
    "A continuación, se muestran los primeros valores de ambos y se procede a realizar las transformaciones necesarias:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    0    1    2    3    4    5    6    7    8    9   ...   36   37   38   39  \\\n0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  1.0  0.0  0.0  0.0   \n1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  1.0  0.0  0.0  0.0   \n2  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  1.0  0.0  0.0  0.0   \n3  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  1.0  0.0  0.0  0.0   \n4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  1.0  0.0  0.0  0.0   \n\n    40   41   42   43   44   45  \n0  0.0  0.0  0.0  1.0  1.0  0.0  \n1  0.0  0.0  0.0  1.0  1.0  0.0  \n2  0.0  0.0  0.0  1.0  1.0  0.0  \n3  0.0  0.0  0.0  1.0  1.0  0.0  \n4  0.0  0.0  0.0  1.0  1.0  0.0  \n\n[5 rows x 46 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>36</th>\n      <th>37</th>\n      <th>38</th>\n      <th>39</th>\n      <th>40</th>\n      <th>41</th>\n      <th>42</th>\n      <th>43</th>\n      <th>44</th>\n      <th>45</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 46 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# Importo to lo necesario para hacer las transformacion\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Instancio el ColumnTransformer para transformar todas las columnas \n",
    "# de texto usando el método OneHotEncoder (devuelve un array)\n",
    "ct = ColumnTransformer([('ohe', OneHotEncoder(sparse=False), columnas_texto)])\n",
    "banco_texto = pd.DataFrame(ct.fit_transform(banco.copy()))\n",
    "\n",
    "print(type(banco_texto))\n",
    "banco_texto.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hago lo mismo pero con las variables numericas para escalarlas\n",
    "# usando el método StandardEncoder para escalar los valores numericos\n",
    "ct = ColumnTransformer([('se', StandardScaler(), columnas_numericas)], remainder='passthrough')\n",
    "columnas_numericas_transf = ct.fit_transform(banco)\n",
    "print(columnas_texto_transf.dtype)\n",
    "\n",
    "combinados = pd.DataFrame(columnas_texto_transf)\n",
    "combinados.head()"
   ]
  },
  {
   "source": [
    "## Referencias:\n",
    "- [Binning][0] con pandas.\n",
    "- Uso de un [Pipeline][1] combinado con el método [ColumnTranformer()][2].\n",
    "\n",
    "[0]:https://www.analyticsvidhya.com/blog/2020/09/pandas-speed-up-preprocessing/\n",
    "[1]: https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html\n",
    "[2]:https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html#sklearn.compose.ColumnTransformer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}