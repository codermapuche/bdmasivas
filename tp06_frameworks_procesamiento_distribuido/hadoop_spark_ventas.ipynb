{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hadoop_spark-ventas.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yG8nP7Wmz9Mr"
      },
      "source": [
        "### Universidad Nacional de Lujan - Bases de Datos Masivas (11088) - Cavasin Nicolas #143501\n",
        "\n",
        "# TP06: Frameworks de procesamiento distribuido\n",
        "\n",
        "## Hadoop MapReduce:\n",
        "El archivo *ventas.txt* posee las ventas de una empresa con los siguientes datos: *id_vendedor*, *id_coordinador*, *cantidad_de_productos_vendidos*, *cantidad_de_dinero*.\n",
        "\n",
        "Genere un esquema bajo el paradigma *MapReduce* para resolver las siguientes consignas:\n",
        "\n",
        "- Produzca un mapper y un reducer para responder cuál es el bonus obtenido por cada vendedor siendo que cada vendedor obtiene el 3% del total del dinero vendido.\n",
        "\n",
        "- Produzca un mapper y un reducer para obtener la cantidad de productos vendidos por cada vendedor, agrupado por coordinador.\n",
        "\n",
        "**Nota:** para facilitar la lectura se ha comentado la impresion por consola. Modificar a gusto.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEEcA_TTzR8o",
        "outputId": "6da48813-ff68-4144-de0f-8e9036b3cd13"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/bdm-unlu/2020/master/TPs/TP06/data/ventas.txt"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-04 03:09:17--  https://raw.githubusercontent.com/bdm-unlu/2020/master/TPs/TP06/data/ventas.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3705191 (3.5M) [text/plain]\n",
            "Saving to: ‘ventas.txt.1’\n",
            "\n",
            "ventas.txt.1        100%[===================>]   3.53M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-12-04 03:09:18 (30.5 MB/s) - ‘ventas.txt.1’ saved [3705191/3705191]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdCV511dMuwc"
      },
      "source": [
        "Para emular el funcionamiento de Hadoop, se utilizarán 3 scripts:\n",
        "\n",
        "1. ``mapper.py``: \n",
        "    - Realiza la transformación al formato deseado ``<key, value>`` quedando ``<id_vendedor, cantidad_de_dinero>``.\n",
        "    - Escribe el resultado a un archivo *01-mapped_a.txt* en formato *.tsv* para que lo consuma el siguiente script.\n",
        "\n",
        "2. ``sorter.py``: \n",
        "    - Ordena la salida del ``script_mapper`` por *id_vendedor*.\n",
        "    - Escribe un nuevo archivo *02-sorted_b.txt* en formato *.tsv*.\n",
        "\n",
        "3. ``reducer.py``:\n",
        "    - Consume la salida del ``script_sorter``.\n",
        "    - Acumula y calcula el 3% del total de dinero que le corresponde a cada *id_vendedor*.\n",
        "    - Escribe los resultados en nuevo archivo *03-reduced_b.txt* en formato *.tsv*.\n",
        "\n",
        "___\n",
        "\n",
        "# Paso 1 - Mapping:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0H57-9u2MmT"
      },
      "source": [
        "# Abro el archivo ventas\n",
        "with open(\"ventas.txt\") as file_hdfs:\n",
        "\n",
        "    # Creo el archivo mapper.txt\n",
        "    with open('01-mapped_a.txt', 'w') as map_file:\n",
        "\n",
        "        # Leo cada linea del archivo\n",
        "        for line in file_hdfs:\n",
        "\n",
        "            # Se eliminan los espacios en blanco iniciales y finales\n",
        "            line = line.strip()\n",
        "\n",
        "            # Separo la linea en palabras y obtengo una lista \n",
        "            words = line.split()\n",
        "\n",
        "            # Imprimo el id_vendedor y cantidad_de_dinero\n",
        "            map_file.write(f'{words[0]}\\t{words[3]}\\n')\n",
        "\n",
        "# 'with' cierra automaticamente todos los archivos"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rB67aMhOQts4"
      },
      "source": [
        "# Paso 2 - Sorting:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_248mfJTFSo"
      },
      "source": [
        "# Abro el archivo mapped\n",
        "with open('01-mapped_a.txt', 'r') as map_file:\n",
        "\n",
        "    # Creo el archivo sorted\n",
        "    with open('02-sorted_a.txt', 'w') as sort_file:\n",
        "\n",
        "        # Ordeno y escribo el nuevo archivo ordenado\n",
        "        for line in sorted(map_file):\n",
        "            sort_file.write(line)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PELk6MFTF4I"
      },
      "source": [
        "# Paso 3 - Reducing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIC99W5rTEbE"
      },
      "source": [
        "# Referencias\n",
        "vendedor_actual = None\n",
        "dinero_actual = 0\n",
        "\n",
        "# Abro el archivo ordenado por id_vendedor\n",
        "with open('02-sorted_a.txt', 'r') as sort_file:\n",
        "\n",
        "    # Creo el archivo reducer\n",
        "    with open('03-reduced_a.txt', 'w') as red_file:\n",
        "\n",
        "        # Por cada linea del sorter\n",
        "        for line in sort_file:\n",
        "\n",
        "            # Obtengo el <key, value> de cada linea \n",
        "            vendedor, dinero = line.split('\\t')\n",
        "\n",
        "            # Convierto dinero a float\n",
        "            dinero = float(dinero)\n",
        "\n",
        "            # Si no hubo un cambio de vendedor acumulo\n",
        "            if vendedor == vendedor_actual:\n",
        "                dinero_actual += dinero\n",
        "            else:\n",
        "                # Si hubo un cambio de vendedor imprimo y actualizo\n",
        "\n",
        "                if vendedor:\n",
        "                    # Calculo el bono\n",
        "                    bono = dinero_actual * 0.03\n",
        "\n",
        "                    # Informo por consola - ELIMINAR COMENTARIO PARA VISUALIZAR\n",
        "                    #print(vendedor_actual, '\\t', bono)\n",
        "\n",
        "                    # Escribo tambien el archivo reduced\n",
        "                    red_file.write(f'{vendedor_actual}\\t{bono}\\n')\n",
        "\n",
        "                    # Modifico los 'actuales'\n",
        "                    vendedor_actual = vendedor\n",
        "                    dinero_actual = dinero\n",
        "\n",
        "\n",
        "# Agrego la ultima linea procesada\n",
        "bono = (dinero_actual + dinero)* 0.03\n",
        "\n",
        "# ELIMINAR COMENTARIO PARA VISUALIZAR\n",
        "# print(vendedor_actual, '\\t', bono)\n",
        "\n",
        "with open('03-reduced_a.txt', 'a') as red_file:\n",
        "    red_file.write(f'{vendedor_actual}\\t{bono}\\n')"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1n8GuO6Kd6JJ"
      },
      "source": [
        "___\n",
        "\n",
        "A continuación se realiza el mismo proceso pero para el punto b:\n",
        "\n",
        "1. ``mapper.py``: \n",
        "    - Realiza la transformación al formato deseado ``<key, value>`` quedando ``<[id_coordinador, id_vendedor], cantidad_de_productos_vendidos>``.\n",
        "    - Escribe el resultado a un archivo *01-mapped_b.txt* en formato *.tsv* para que lo consuma el siguiente script.\n",
        "\n",
        "2. ``sorter.py``: \n",
        "    - Ordena la salida del ``script_mapper`` por *id_coordinador* + *id_vendedor*.\n",
        "    - Escribe un nuevo archivo *02-sorted_b.txt* en formato *.tsv*.\n",
        "\n",
        "3. ``reducer.py``:\n",
        "    - Consume la salida del ``script_sorter``.\n",
        "    - Calcula el total de productos vendidos agrupados por coordinador y vendedor.\n",
        "    - Escribe los resultados en nuevo archivo *03-reduced_b.txt* en formato *.tsv*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSGpD2Z3egul"
      },
      "source": [
        "# Abro el archivo ventas\n",
        "with open(\"ventas.txt\") as file_hdfs:\n",
        "\n",
        "    # Creo el archivo mapper.txt\n",
        "    with open('01-mapped_b.txt', 'w') as map_file:\n",
        "\n",
        "        # Leo cada linea del archivo\n",
        "        for line in file_hdfs:\n",
        "\n",
        "            # Se eliminan los espacios en blanco iniciales y finales\n",
        "            line = line.strip()\n",
        "\n",
        "            # Separo la linea en palabras y obtengo una lista \n",
        "            words = line.split()\n",
        "\n",
        "            # Imprimo el id_coordinador, id_vendedor y cantidad_de_productos_vendidos\n",
        "            map_file.write(f'{words[1]}\\t{words[0]}\\t{words[2]}\\n')\n",
        "\n",
        "# 'with' cierra automaticamente todos los archivos\n",
        "\n",
        "# Abro el archivo mapped\n",
        "with open('01-mapped_b.txt', 'r') as map_file:\n",
        "\n",
        "    # Creo el archivo sorted\n",
        "    with open('02-sorted_b.txt', 'w') as sorted_file:\n",
        "\n",
        "        # Ordeno y escribo el nuevo archivo ordenado\n",
        "        for line in sorted(map_file):\n",
        "            sorted_file.write(line)\n",
        "\n",
        "# Referencias\n",
        "coordinador_actual = None\n",
        "vendedor_actual = None\n",
        "cantidad_actual = 0\n",
        "\n",
        "# Abro el archivo ordenado por id_vendedor\n",
        "with open('02-sorted_b.txt', 'r') as sorted_file:\n",
        "\n",
        "    # Creo el archivo reducer\n",
        "    with open('03-reduced_b.txt', 'w') as red_file:\n",
        "\n",
        "        # Por cada linea del sorted\n",
        "        for line in sorted_file:\n",
        "\n",
        "            # Obtengo el <key, value> de cada linea \n",
        "            coordinador, vendedor, cantidad = line.split('\\t')\n",
        "\n",
        "            # Convierto de string a integer\n",
        "            cantidad = int(dinero)\n",
        "\n",
        "            # Si no hubo un cambio de clave, acumulo\n",
        "            if coordinador == coordinador_actual and vendedor == vendedor_actual:\n",
        "                cantidad_actual += cantidad\n",
        "            else:\n",
        "                # Si hubo un cambio de coordinador/vendedor imprimo y actualizo\n",
        "\n",
        "                # Informo por consola - ELIMINAR COMENTARIO PARA VISUALIZAR\n",
        "                # print(coordinador_actual, '\\t', vendedor_actual, '\\t', cantidad_actual)\n",
        "\n",
        "                # Escribo tambien el archivo reduced\n",
        "                red_file.write(f'{coordinador_actual}\\t{vendedor_actual}\\t{cantidad_actual}\\n')\n",
        "\n",
        "                # Modifico los 'actuales'\n",
        "                coordinador_actual = coordinador\n",
        "                vendedor_actual = vendedor\n",
        "                cantidad_actual = cantidad\n",
        "\n",
        "# Agrego la ultima linea procesada - ELIMINAR COMENTARIO PARA VISUALIZAR\n",
        "# print(coordinador_actual, '\\t', vendedor_actual, '\\t', cantidad_actual+cantidad)\n",
        "\n",
        "with open('03-reduced_b.txt', 'a') as red_file:\n",
        "    red_file.write(f'{coordinador_actual}\\t{vendedor_actual}\\t{cantidad_actual+cantidad}\\n')"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJ4728Rtv-pC"
      },
      "source": [
        "## Apache Spark con PySpark:\n",
        "Resuelva el ejercicio anterior con PySpark.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BLdDdr6zNK_",
        "outputId": "0a91d6bc-1f72-4b5c-9ae6-6c5809c15b7f"
      },
      "source": [
        "# Instalo pyspark y configuro el entorno\n",
        "!pip install pyspark\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.6/dist-packages (3.0.1)\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.6/dist-packages (from pyspark) (0.10.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "L610N4Cu0aUC",
        "outputId": "e080f40b-752e-4e25-8ce5-12e7197f6035"
      },
      "source": [
        "# Importo Spark\n",
        "from pyspark import SparkConf, SparkContext\n",
        "\n",
        "# Seteo el master al entorno local y defino el nombre de la app para identificarla\n",
        "conf = SparkConf().setMaster(\"local\").setAppName(\"Bono vendedores\")\n",
        "\n",
        "# Inicializo el Spark Context\n",
        "sc = SparkContext(conf = conf)\n",
        "\n",
        "# Verifico inicializacion\n",
        "sc"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://6e01f72a7be4:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.0.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Bono vendedores</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ],
            "text/plain": [
              "<SparkContext master=local appName=Bono vendedores>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgmv7KtK0aNS",
        "outputId": "4b640ad0-9613-4d38-a083-5b2e11459dea"
      },
      "source": [
        "# Leo el archivo de ventas y separo cada valor \n",
        "rdd_ventas = sc.textFile(\"ventas.txt\").\\\n",
        "                map(lambda line: line.split(\"\\t\"))\n",
        "\n",
        "# Muestro la primer linea del archivo\n",
        "print(f'Primer linea del archivo: {rdd_ventas.first()}')\n",
        "print(f'Ocurrencias en archivo: {rdd_ventas.count()}.\\n')\n",
        "\n",
        "# Mapeo seleccionando id_vendedor y cantidad_de_dinero (columnas 0 y 3)\n",
        "# Ademas convierto dinero a float y ordeno por id_vendedor\n",
        "rdd_vendedor_dinero = rdd_ventas.\\\n",
        "                        map(lambda values: (values[0], float(values[3]))).\\\n",
        "                        sortByKey()\n",
        "\n",
        "# Muestro el primer mapeo\n",
        "print(f'Primer elemento del mapper: <{rdd_vendedor_dinero.first()}>')\n",
        "print(f'Ocurrencias en mapper: {rdd_vendedor_dinero.count()}.\\n')\n",
        "\n",
        "# Ahora reduzco por id_vendedor y acumulo el dinero\n",
        "rdd_vendedor_dinero = rdd_vendedor_dinero.reduceByKey(lambda id, dinero: id +dinero)\n",
        "\n",
        "# Mapeo nuevamente para poder aplicar una multiplicacion y asi\n",
        "# calcular el bono de cada vendedor\n",
        "rdd_vendedor_bono = rdd_vendedor_dinero.map(lambda values: (values[0], values[1]*0.03))\n",
        "\n",
        "# Muestro primer reduccion y ocurrencias\n",
        "print(f'Primer elemento del reducer: <{rdd_vendedor_bono.first()}>')\n",
        "print(f'Ocurrencias en reducer: {rdd_vendedor_bono.count()}.')\n",
        "print()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Primer linea del archivo: ['17493', '6012', '21', '207.509827822219']\n",
            "Ocurrencias en archivo: 119582.\n",
            "\n",
            "Primer elemento del mapper: <('100', 341.811971935356)>\n",
            "Ocurrencias en mapper: 119582.\n",
            "\n",
            "Primer elemento del reducer: <('100', 286.54551868222)>\n",
            "Ocurrencias en reducer: 15522.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VJzWYt3cVQf"
      },
      "source": [
        "Por último se muestra todo el contenido del RDD. Es decir, todos los pares ``<id_vendedor, bono>``:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYm5IghuXo7K"
      },
      "source": [
        "# Muestro todos los id_vendedor con su correspondiente bono\n",
        "for vendedor in rdd_vendedor_bono.collect():\n",
        "    print(vendedor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dkmpFoJcmRH"
      },
      "source": [
        "\n",
        "___\n",
        "\n",
        "\n",
        "A continuación se realiza el punto b:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iCYHKCGcl3O",
        "outputId": "441be33d-467a-4bf0-a6a4-b4a78cac4034"
      },
      "source": [
        "# Reutilizo el rdd del punto anterior \n",
        "# Mapeo <[id_coordinador, id_vendedor], cantidad_productos_vendidos> \n",
        "# Ademas, convierto cantidades a integer y ordeno por clave\n",
        "rdd_coord_ventas = rdd_ventas.map(lambda values: ((values[1], values[0]), int(values[2]))).sortByKey()\n",
        "\n",
        "# Muestro el primer mapeo\n",
        "print(f'Primer elemento del mapper: <{rdd_coord_ventas.first()}>')\n",
        "print(f'Ocurrencias en mapper: {rdd_coord_ventas.count()}.')\n",
        "print()\n",
        "\n",
        "# Acumulo las cantidades por clave\n",
        "rdd_coord_cantidades = rdd_coord_ventas.reduceByKey(lambda coord, cant: coord  +cant)\n",
        "\n",
        "# Muestro la primer reduccion\n",
        "print(f'Primer elemento del reducer: <{rdd_coord_cantidades.first()}>')\n",
        "print(f'Ocurrencias en reducer: {rdd_coord_cantidades.count()}.')\n",
        "print()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Primer elemento del mapper: <(('10008', '11947'), 50)>\n",
            "Ocurrencias en mapper: 119582.\n",
            "\n",
            "Primer elemento del reducer: <(('10008', '11947'), 292)>\n",
            "Ocurrencias en reducer: 15522.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZMxeEBgocf7"
      },
      "source": [
        "# Muestro todo el contenido del rdd reducido\n",
        "for val in rdd_coord_cantidades.collect():\n",
        "    print(val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeOaN4I4ob0D"
      },
      "source": [
        "# Finalizo la aplicacion\n",
        "sc.stop()"
      ],
      "execution_count": 72,
      "outputs": []
    }
  ]
}