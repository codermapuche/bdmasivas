{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.6 64-bit",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### Universidad Nacional de Lujan - Bases de Datos Masivas (11088) - Cavasin Nicolas #143501\n",
    "# TP05-01 - Árboles de decisión\n",
    "\n",
    "### Ejercicio 4:\n",
    "Se provee la base de datos de los pasajeros del famoso barco que se hundiera en su viaje inaugural (archivo titanic-en.csv) con los siguientes atributos y valores posibles: \n",
    "- Class {\"1st\",\"2nd\",\"3rd\",\"crew\"}\n",
    "- Age {\"adult\",\"child\"} \n",
    "- Sex {\"male\",\"female\"}\n",
    "- Survived {\"yes\",\"no\"}\n",
    "\n",
    "Genere el árbol de clasificación, explore la solución dada y las posibles alternativas para obtener un nuevo árbol que clasifique “mejor”.\n",
    "    "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "--2020-11-12 20:53:12--  https://raw.githubusercontent.com/bdm-unlu/2020/master/TPs/TP05/TP0501/titanic-en.csv\nLoaded CA certificate &#39;/etc/ssl/certs/ca-certificates.crt&#39;\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.216.133\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.216.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 42177 (41K) [text/plain]\nSaving to: &#39;titanic-en.csv&#39;\n\ntitanic-en.csv      100%[===================&gt;]  41.19K  --.-KB/s    in 0.03s   \n\n2020-11-12 20:53:12 (1.28 MB/s) - &#39;titanic-en.csv&#39; saved [42177/42177]\n\n"
    }
   ],
   "source": [
    "! rm titanic-en.csv\n",
    "!wget https://raw.githubusercontent.com/bdm-unlu/2020/master/TPs/TP05/TP0501/titanic-en.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Cantidad de tuplas: 2201\n\nCantidad de columnas: 4\n\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  class    age   sex survived\n0   1st  adult  male      yes\n1   1st  adult  male      yes\n2   1st  adult  male      yes\n3   1st  adult  male      yes\n4   1st  adult  male      yes",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>age</th>\n      <th>sex</th>\n      <th>survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1st</td>\n      <td>adult</td>\n      <td>male</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1st</td>\n      <td>adult</td>\n      <td>male</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1st</td>\n      <td>adult</td>\n      <td>male</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1st</td>\n      <td>adult</td>\n      <td>male</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1st</td>\n      <td>adult</td>\n      <td>male</td>\n      <td>yes</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Importo pandas para lectura\n",
    "import pandas as pd\n",
    "\n",
    "# Leo el archivo\n",
    "titanic = pd.read_csv('titanic-en.csv')\n",
    "\n",
    "# Muestro sus dimensiones\n",
    "print(f'Cantidad de tuplas: {titanic.shape[0]}\\n')\n",
    "print(f'Cantidad de columnas: {titanic.shape[1]}\\n')\n",
    "\n",
    "titanic.head()"
   ]
  },
  {
   "source": [
    "Se observa que todas las columnas son de tipo *String* (todas categóricas a excepción de la columna *class*) por lo tanto todas deben ser transformadas para poder luego crear el modelo de predicción. Para ello, se utilizará el método *LabelEncoder* -para las columnas categóricas- y adicionalmente el método *OneHotEncoder* (para la columna *class*) dando como resultado una columna binaria por cada valor diferente, una suerte de bitmap de valores (ver referencias)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     0    1    2    3  age  sex\n0  1.0  0.0  0.0  0.0    0    1\n1  1.0  0.0  0.0  0.0    0    1\n2  1.0  0.0  0.0  0.0    0    1\n3  1.0  0.0  0.0  0.0    0    1\n4  1.0  0.0  0.0  0.0    0    1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>age</th>\n      <th>sex</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Importo el metodo\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Importo el encoder\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Instancio los encoders\n",
    "le = LabelEncoder()\n",
    "ohe = OneHotEncoder(sparse=True)\n",
    "\n",
    "# Copio el dataset\n",
    "copia = titanic.copy()\n",
    "\n",
    "# Defino el target y lo saco del dataset a transformar\n",
    "target = copia.pop('survived')\n",
    "target_name = target.name\n",
    "\n",
    "# Elimino la columna class del dataframe\n",
    "col_class = copia.pop('class')\n",
    "\n",
    "# Aplico LabelEncoder a todas las columnas\n",
    "for col in copia.columns:\n",
    "    copia[col] = le.fit_transform(copia[col])\n",
    "\n",
    "## Inicio la transformacion de la columna class\n",
    "# LabelEncoder - Analizo los dif valores de las clases de class \n",
    "le.fit(col_class)\n",
    "\n",
    "# Labelencoder - Transformo las clases de class y le doy forma de columna \n",
    "class_as_int = le.transform(le.classes_).reshape(4, 1)\n",
    "\n",
    "# OneHotEncoder - Creo una columna binaria por cada valor \n",
    "# diferente que el LabelEncoder haya generado sobre las classes\n",
    "ohe.fit(class_as_int)\n",
    "\n",
    "# Me guardo el numero de tuplas del dataframe\n",
    "rows = copia.shape[0]\n",
    "\n",
    "# LabelEncoder - Transformo los datos de str a integer y \n",
    "# le doy forma de columna\n",
    "class_le = le.transform(col_class).reshape(rows, 1)\n",
    "\n",
    "# OneHotEncoder - Creo una columna binaria por cada valor \n",
    "# diferente que el LabelEncoder haya generado sobre los datos \n",
    "class_ohe = pd.DataFrame(ohe.transform(class_le).toarray())\n",
    "\n",
    "# Agrego el resultado de la transformacion al dataframe\n",
    "titanic_transf = pd.concat([class_ohe, copia], axis=1)\n",
    "\n",
    "# Me guardo el nombre de las features\n",
    "features_names = list(le.classes_)\n",
    "features_names.append('age')\n",
    "features_names.append('sex')\n",
    "\n",
    "# Defino las features\n",
    "features = titanic_transf\n",
    "\n",
    "# Muestro el resultado final\n",
    "titanic_transf.head()"
   ]
  },
  {
   "source": [
    "Como se observa, el dataset ha sido completamente transformado a valores discretos.\n",
    "\n",
    "Esta listo para ser procesado con el fin de crear el árbol de decisión que determine si -dado el sexo, la edad y la clase en la que viajaban- el pasajero sobrevive o no al hundimiento del barco."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Se muestran los primeros 10 resultados\n\n#   | Predicción     | Original   |\n===================================\n0   | no             | yes        |\n-----------------------------------\n1   | yes            | yes        |\n-----------------------------------\n2   | no             | no         |\n-----------------------------------\n3   | no             | yes        |\n-----------------------------------\n4   | no             | no         |\n-----------------------------------\n5   | no             | no         |\n-----------------------------------\n6   | no             | yes        |\n-----------------------------------\n7   | no             | no         |\n-----------------------------------\n8   | no             | no         |\n-----------------------------------\n9   | no             | yes        |\n-----------------------------------\n\nPrecisión del modelo: 0.7858439201451906\n\nReporte de clasificación: \n              precision    recall  f1-score   support\n\n          no       0.76      0.98      0.86       365\n         yes       0.93      0.40      0.56       186\n\n    accuracy                           0.79       551\n   macro avg       0.84      0.69      0.71       551\nweighted avg       0.82      0.79      0.76       551\n\n"
    }
   ],
   "source": [
    "# Importo la libreria que permite separar en training set y test set\n",
    "from sklearn.model_selection import train_test_split as s\n",
    "\n",
    "# Importo el arbol\n",
    "from sklearn import tree\n",
    "\n",
    "# Importo libreria para graficar\n",
    "import graphviz\n",
    "\n",
    "# Importo las metricas para testear el modelo\n",
    "from sklearn import metrics\n",
    "\n",
    "# Divido el dataset en 75-25 para training y test respectivamente\n",
    "features_train, features_test, target_train, target_test = s(features, target, random_state=0, test_size=0.25)\n",
    "\n",
    "# Instancio el arbol por entropia\n",
    "t = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "\n",
    "# Lo entreno\n",
    "t.fit(features_train, target_train)\n",
    "\n",
    "# Almaceno el modelo en formato DOT\n",
    "titanic_dot = tree.export_graphviz(t\n",
    "                    , out_file=None\n",
    "                    , feature_names=features_names\n",
    "                    , class_names=target.name\n",
    "                    , label='all'\n",
    "                    , filled=True, rounded=True\n",
    "                    , special_characters=True)\n",
    "\n",
    "# Tambien lo guardo como PNG\n",
    "graph = graphviz.Source(titanic_dot)\n",
    "graph.format = 'png'\n",
    "graph.render('titanic')\n",
    "\n",
    "# Obtengo la prediccion con el set de prueba definido anteriormente\n",
    "le.fit(titanic['survived'])\n",
    "prediccion = t.predict(features_test)\n",
    "\n",
    "# Convierto a array para poder imprimirlo + facil\n",
    "target_test = pd.array(target_test)\n",
    "\n",
    "print(f'Se muestran los primeros 10 resultados\\n')\n",
    "\n",
    "# Muestro prediccion vs original\n",
    "header = '{:<4}{:<2}{:<15}{:<2}{:<11}{}'.format('#', '|', 'Predicción', '|', 'Original','|')\n",
    "print(header)\n",
    "print('='*35, end='')\n",
    "sep = '|'\n",
    "for i in range(10):\n",
    "    print(f\"\\n{str(i).ljust(4, ' ')}{sep.ljust(2, ' ')}{prediccion[i].ljust(15, ' ')}{sep.ljust(2, ' ')}{target_test[i].ljust(11, ' ')}{sep}\\n\", end='-'*35)\n",
    "\n",
    "# Veo qué tan acertado estuvo\n",
    "print(f'\\n\\nPrecisión del modelo: {metrics.accuracy_score(target_test, prediccion)}', end='\\n\\n')\n",
    "\n",
    "# Muestro un reporte de clasificación con diferentes métricas sobre cada feature \n",
    "print(f'Reporte de clasificación: \\n{metrics.classification_report(target_test, prediccion)}')\n",
    "\n"
   ]
  },
  {
   "source": [
    "Árbol de clasificación del dataset *titanic-en.csv*:\n",
    "\n",
    "![Arbol](titanic.png)"
   ],
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   }
  },
  {
   "source": [
    "***Observaciones:***\n",
    "- El árbol resultante tiene una profundidad de 5 niveles.\n",
    "- Tiene una precisión de clasificación del 78.5%.\n",
    "- Falla más frecuentemente en la predicción de los quién no sobrevivirá. Es decir, es pesimista.\n",
    "- La hoja con menos samples posee 1.\n",
    "\n",
    "___\n",
    "\n",
    "\n",
    "Para intentar mejorar su precisión, se intentarán las siguientes modificaciones:\n",
    "- Poda de niveles con máximo 2.\n",
    "- Límite mínimo de samples por hoja en 200.\n",
    "- Árbol que clasifique aplicando Gini.\n",
    "- Modificación del porcentaje de splitting entre sets de test y training (60%-40%) junto con aleatorización de los valores que cada uno utiliza (``random_state=33``) ."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n\nPrecisión del modelo: 0.778584392014519\n\nReporte de clasificación: \n              precision    recall  f1-score   support\n\n          no       0.76      0.98      0.85       365\n         yes       0.92      0.38      0.53       186\n\n    accuracy                           0.78       551\n   macro avg       0.84      0.68      0.69       551\nweighted avg       0.81      0.78      0.75       551\n\n"
    }
   ],
   "source": [
    "# Divido el dataset en 75-25 para training y test respectivamente\n",
    "features_train, features_test, target_train, target_test = s(features, target, random_state=0, test_size=0.25)\n",
    "\n",
    "# Instancio el arbol por entropia\n",
    "t2 = tree.DecisionTreeClassifier(criterion='entropy', max_depth=2)\n",
    "\n",
    "# Lo entreno\n",
    "t2.fit(features_train, target_train)\n",
    "\n",
    "# Almaceno el modelo en formato DOT\n",
    "titanic_dot = tree.export_graphviz(t2\n",
    "                    , out_file=None\n",
    "                    , feature_names=features_names\n",
    "                    , class_names=target_name\n",
    "                    , label='all'\n",
    "                    , filled=True, rounded=True\n",
    "                    , special_characters=True)\n",
    "\n",
    "# Tambien lo guardo como PNG\n",
    "graph = graphviz.Source(titanic_dot)\n",
    "graph.format = 'png'\n",
    "graph.render('titanic_max_level')\n",
    "\n",
    "# Obtengo la prediccion con el set de prueba definido anteriormente\n",
    "prediccion2 = t2.predict(features_test)\n",
    "\n",
    "# Veo qué tan acertado estuvo\n",
    "print(f'\\n\\nPrecisión del modelo: {metrics.accuracy_score(target_test, prediccion2)}', end='\\n\\n')\n",
    "\n",
    "# Muestro un reporte de clasificación con diferentes métricas sobre cada feature \n",
    "print(f'Reporte de clasificación: \\n{metrics.classification_report(target_test, prediccion2)}')\n",
    "\n"
   ]
  },
  {
   "source": [
    "Árbol número 2: cantidad máxima de niveles = 2.\n",
    "\n",
    "![Arbol](titanic_max_level.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n\nPrecisión del modelo: 0.7658802177858439\n\nReporte de clasificación: \n              precision    recall  f1-score   support\n\n          no       0.78      0.91      0.84       365\n         yes       0.73      0.49      0.59       186\n\n    accuracy                           0.77       551\n   macro avg       0.75      0.70      0.71       551\nweighted avg       0.76      0.77      0.75       551\n\n"
    }
   ],
   "source": [
    "# Divido el dataset en 75-25 para training y test respectivamente\n",
    "features_train, features_test, target_train, target_test = s(features, target, random_state=0, test_size=0.25)\n",
    "\n",
    "# Instancio el arbol por entropia\n",
    "t3 = tree.DecisionTreeClassifier(criterion='entropy', min_samples_leaf=200)\n",
    "\n",
    "# Lo entreno\n",
    "t3.fit(features_train, target_train)\n",
    "\n",
    "# Almaceno el modelo en formato DOT\n",
    "titanic_dot = tree.export_graphviz(t3\n",
    "                    , out_file=None\n",
    "                    , feature_names=features_names\n",
    "                    , class_names=target_name\n",
    "                    , label='all'\n",
    "                    , filled=True, rounded=True\n",
    "                    , special_characters=True)\n",
    "\n",
    "# Tambien lo guardo como PNG\n",
    "graph = graphviz.Source(titanic_dot)\n",
    "graph.format = 'png'\n",
    "graph.render('titanic_min_samples')\n",
    "\n",
    "# Obtengo la prediccion con el set de prueba definido anteriormente\n",
    "prediccion3 = t3.predict(features_test)\n",
    "\n",
    "# Veo qué tan acertado estuvo\n",
    "print(f'\\n\\nPrecisión del modelo: {metrics.accuracy_score(target_test, prediccion3)}', end='\\n\\n')\n",
    "\n",
    "# Muestro un reporte de clasificación con diferentes métricas sobre cada feature \n",
    "print(f'Reporte de clasificación: \\n{metrics.classification_report(target_test, prediccion3)}')\n",
    "\n"
   ]
  },
  {
   "source": [
    "Árbol número 3: cantidad mínima de samples por hoja = 200.\n",
    "\n",
    "![Arbol](titanic_min_samples.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n\nPrecisión del modelo: 0.7858439201451906\n\nReporte de clasificación: \n              precision    recall  f1-score   support\n\n          no       0.76      0.98      0.86       365\n         yes       0.93      0.40      0.56       186\n\n    accuracy                           0.79       551\n   macro avg       0.84      0.69      0.71       551\nweighted avg       0.82      0.79      0.76       551\n\n"
    }
   ],
   "source": [
    "# Divido el dataset en 75-25 para training y test respectivamente\n",
    "features_train, features_test, target_train, target_test = s(features, target, random_state=0, test_size=0.25)\n",
    "\n",
    "# Instancio el arbol por entropia\n",
    "t4 = tree.DecisionTreeClassifier(criterion='gini')\n",
    "\n",
    "# Lo entreno\n",
    "t4.fit(features_train, target_train)\n",
    "\n",
    "# Almaceno el modelo en formato DOT\n",
    "titanic_dot = tree.export_graphviz(t4\n",
    "                    , out_file=None\n",
    "                    , feature_names=features_names\n",
    "                    , class_names=target_name\n",
    "                    , label='all'\n",
    "                    , filled=True, rounded=True\n",
    "                    , special_characters=True)\n",
    "\n",
    "# Tambien lo guardo como PNG\n",
    "graph = graphviz.Source(titanic_dot)\n",
    "graph.format = 'png'\n",
    "graph.render('titanic_gini')\n",
    "\n",
    "# Obtengo la prediccion con el set de prueba definido anteriormente\n",
    "prediccion4 = t4.predict(features_test)\n",
    "\n",
    "# Veo qué tan acertado estuvo\n",
    "print(f'\\n\\nPrecisión del modelo: {metrics.accuracy_score(target_test, prediccion4)}', end='\\n\\n')\n",
    "\n",
    "# Muestro un reporte de clasificación con diferentes métricas sobre cada feature \n",
    "print(f'Reporte de clasificación: \\n{metrics.classification_report(target_test, prediccion4)}')\n",
    "\n"
   ]
  },
  {
   "source": [
    "Árbol número 4: clasificación aplicando el criterio *Gini*.\n",
    "\n",
    "![Arbol](titanic_gini.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n\nPrecisión del modelo: 0.8047673098751419\n\nReporte de clasificación: \n              precision    recall  f1-score   support\n\n          no       0.78      0.99      0.87       595\n         yes       0.94      0.43      0.59       286\n\n    accuracy                           0.80       881\n   macro avg       0.86      0.71      0.73       881\nweighted avg       0.83      0.80      0.78       881\n\n"
    }
   ],
   "source": [
    "# Divido el dataset en 60-40 para training y test respectivamente\n",
    "features_train, features_test, target_train, target_test = s(features, target, random_state=33, test_size=0.4)\n",
    "\n",
    "# Instancio el arbol por entropia\n",
    "t5 = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "\n",
    "# Lo entreno\n",
    "t5.fit(features_train, target_train)\n",
    "\n",
    "# Almaceno el modelo en formato DOT\n",
    "titanic_dot = tree.export_graphviz(t5\n",
    "                    , out_file=None\n",
    "                    , feature_names=features_names\n",
    "                    , class_names=target_name\n",
    "                    , label='all'\n",
    "                    , filled=True, rounded=True\n",
    "                    , special_characters=True)\n",
    "\n",
    "# Tambien lo guardo como PNG\n",
    "graph = graphviz.Source(titanic_dot)\n",
    "graph.format = 'png'\n",
    "graph.render('titanic_split')\n",
    "\n",
    "# Obtengo la prediccion con el set de prueba definido anteriormente\n",
    "prediccion5 = t5.predict(features_test)\n",
    "\n",
    "# Veo qué tan acertado estuvo\n",
    "print(f'\\n\\nPrecisión del modelo: {metrics.accuracy_score(target_test, prediccion5)}', end='\\n\\n')\n",
    "\n",
    "# Muestro un reporte de clasificación con diferentes métricas sobre cada feature \n",
    "print(f'Reporte de clasificación: \\n{metrics.classification_report(target_test, prediccion5)}')"
   ]
  },
  {
   "source": [
    "Árbol número 5: set de training del 60% del dataset y una aleatorización de selección con la semilla iniciada en el número 33.\n",
    "\n",
    "![Arbol](titanic_split.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Conclusiones:\n",
    "- El árbol que mayor precisión alcanzó fué el último, donde se disminuyó el set de training al 60% del dataset y se le dió un valor de aleatorización a la selección de registros con la semilla iniciada en el número 33. Este modelo llega al 80.4% de precisión.\n",
    "\n",
    "- El modelo menos preciso (76.5%) es el que fué instanciado con una cantidad mínima de 200 samples por hoja. Su retracción de niveles impide una buena clasificación.\n",
    "\n",
    "- Lo mismo sucedió con el modelo cuyo máximo límite de niveles fué 2, la poda es excesiva y se terminan eliminando features (i.e.: *crew*).\n",
    "\n",
    "- Por último, el modelo que clasifica utilizando el criterio *Gini* obtuvo la misma precisión que el modelo original: 78.5%."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Referencias:\n",
    "\n",
    "- Utilización del método [OneHotencoder()][0].\n",
    "\n",
    "[0]:https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html?highlight=one%20hot%20encoder#sklearn.preprocessing.OneHotEncoder"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}