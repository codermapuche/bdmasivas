{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.6 64-bit",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### Universidad Nacional de Lujan - Bases de Datos Masivas (11088) - Cavasin Nicolas #143501\n",
    "# TP05-01 - Árboles de decisión\n",
    "\n",
    "### Ejercicio 2:\n",
    "Trabaje con el dataset de Scikit Learn “wine”:\n",
    "\n",
    "- Utilice el metadata que provee la librería, ¿Cuál es el tema que aborda el dataset?\n",
    "\n",
    "- Genere el árbol de decisión que permita clasificar los diferentes tipos de vino utilizando un muestreo con proporciones de 80% para entrenamiento y 20% para testeo.\n",
    "\n",
    "- Explore la solución dada y las posibles configuraciones para obtener un nuevo árbol que clasifique “mejor”. Documente las conclusiones."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "--2020-11-06 17:23:08--  https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\nLoaded CA certificate &#39;/etc/ssl/certs/ca-certificates.crt&#39;\nResolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\nConnecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 10782 (11K) [application/x-httpd-php]\nSaving to: &#39;wine.data&#39;\n\nwine.data           100%[===================&gt;]  10.53K  --.-KB/s    in 0.005s  \n\n2020-11-06 17:23:11 (1.96 MB/s) - &#39;wine.data&#39; saved [10782/10782]\n\n"
    }
   ],
   "source": [
    "# Obtengo el dataset\n",
    "!rm wine.data\n",
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": ".. _wine_dataset:\n\nWine recognition dataset\n------------------------\n\n**Data Set Characteristics:**\n\n    :Number of Instances: 178 (50 in each of three classes)\n    :Number of Attributes: 13 numeric, predictive attributes and the class\n    :Attribute Information:\n \t\t- Alcohol\n \t\t- Malic acid\n \t\t- Ash\n\t\t- Alcalinity of ash  \n \t\t- Magnesium\n\t\t- Total phenols\n \t\t- Flavanoids\n \t\t- Nonflavanoid phenols\n \t\t- Proanthocyanins\n\t\t- Color intensity\n \t\t- Hue\n \t\t- OD280/OD315 of diluted wines\n \t\t- Proline\n\n    - class:\n            - class_0\n            - class_1\n            - class_2\n\t\t\n    :Summary Statistics:\n    \n    ============================= ==== ===== ======= =====\n                                   Min   Max   Mean     SD\n    ============================= ==== ===== ======= =====\n    Alcohol:                      11.0  14.8    13.0   0.8\n    Malic Acid:                   0.74  5.80    2.34  1.12\n    Ash:                          1.36  3.23    2.36  0.27\n    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n    Magnesium:                    70.0 162.0    99.7  14.3\n    Total Phenols:                0.98  3.88    2.29  0.63\n    Flavanoids:                   0.34  5.08    2.03  1.00\n    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n    Proanthocyanins:              0.41  3.58    1.59  0.57\n    Colour Intensity:              1.3  13.0     5.1   2.3\n    Hue:                          0.48  1.71    0.96  0.23\n    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n    Proline:                       278  1680     746   315\n    ============================= ==== ===== ======= =====\n\n    :Missing Attribute Values: None\n    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n    :Creator: R.A. Fisher\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n    :Date: July, 1988\n\nThis is a copy of UCI ML Wine recognition datasets.\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n\nThe data is the results of a chemical analysis of wines grown in the same\nregion in Italy by three different cultivators. There are thirteen different\nmeasurements taken for different constituents found in the three types of\nwine.\n\nOriginal Owners: \n\nForina, M. et al, PARVUS - \nAn Extendible Package for Data Exploration, Classification and Correlation. \nInstitute of Pharmaceutical and Food Analysis and Technologies,\nVia Brigata Salerno, 16147 Genoa, Italy.\n\nCitation:\n\nLichman, M. (2013). UCI Machine Learning Repository\n[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\nSchool of Information and Computer Science. \n\n.. topic:: References\n\n  (1) S. Aeberhard, D. Coomans and O. de Vel, \n  Comparison of Classifiers in High Dimensional Settings, \n  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n  Mathematics and Statistics, James Cook University of North Queensland. \n  (Also submitted to Technometrics). \n\n  The data was used with many others for comparing various \n  classifiers. The classes are separable, though only RDA \n  has achieved 100% correct classification. \n  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n  (All results using the leave-one-out technique) \n\n  (2) S. Aeberhard, D. Coomans and O. de Vel, \n  &quot;THE CLASSIFICATION PERFORMANCE OF RDA&quot; \n  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n  Mathematics and Statistics, James Cook University of North Queensland. \n  (Also submitted to Journal of Chemometrics).\n\n"
    }
   ],
   "source": [
    "# Importo el dataset desde scikit\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "# Lo cargo\n",
    "vinos = load_wine()\n",
    "\n",
    "# Muestro su descripcion\n",
    "print(vinos.DESCR)"
   ]
  },
  {
   "source": [
    "Se puede observar que:\n",
    "- El dataset fué creado en julio de 1988 por Michael Marshall.\n",
    "- Representa los resultados de un análisis químico de fermentación de vinos en la misma región de Italia realizada por tres bodegas diferentes.\n",
    "- Puede ser accedido públicamente desde [aquí](https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data).\n",
    "- Contiene 178 instancias de diferentes tipos de vinos separados en tres clases: *class_0*, *class_1*, *class_2*.\n",
    "- Todos sus atributos son numéricos (a excepción de la descripción de cada columna) y no posee ningún valor faltante.\n",
    "\n",
    "El valor agregado de la versión de scikit es que viene con un *poco* de pre-procesamiento. El target y los features ya se encuentran separados y los números son representados utilizado ``numpy`` en vez de *integer*s o *float*s."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Predicción: \t[0 2 1 0 1 1 0 2 1 1 2 2 0 1 2 1 0 0 2 0 1 0 1 1 1 1 1 1 1 2 0 0 1 0 0 0]\nTarget: \t[0 2 1 0 1 1 0 2 1 1 2 2 0 1 2 1 0 0 1 0 1 0 0 1 1 1 1 1 1 2 0 0 1 0 0 0]\n\nPrecisión del modelo: 0.9444444444444444\n\nReporte de clasificación: \n              precision    recall  f1-score   support\n\n           0       1.00      0.93      0.96        14\n           1       0.94      0.94      0.94        16\n           2       0.86      1.00      0.92         6\n\n    accuracy                           0.94        36\n   macro avg       0.93      0.96      0.94        36\nweighted avg       0.95      0.94      0.94        36\n\n"
    }
   ],
   "source": [
    "# Importo el divisor de training y tests\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importo el arbol\n",
    "from sklearn import tree\n",
    "\n",
    "# Importo libreria para graficar\n",
    "import graphviz\n",
    "\n",
    "# Importo las metricas para testear el modelo\n",
    "from sklearn import metrics\n",
    "\n",
    "# Divido el dataset 80-20 como pide el enunciado\n",
    "features_train, features_test, target_train, target_test = train_test_split(vinos.data, vinos.target, random_state=0, test_size=0.2)\n",
    "\n",
    "# Instancio el arbol por entropia\n",
    "t = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "\n",
    "# Lo entreno\n",
    "t.fit(features_train, target_train)\n",
    "\n",
    "# Almaceno el modelo en formato DOT\n",
    "vinos_dot = tree.export_graphviz(t\n",
    "                    , out_file=None\n",
    "                    , feature_names=vinos.feature_names\n",
    "                    , class_names=vinos.target_names\n",
    "                    , filled=True, rounded=True\n",
    "                    , special_characters=True)\n",
    "\n",
    "# Tambien lo guardo como PNG\n",
    "graph = graphviz.Source(vinos_dot)\n",
    "graph.format = 'png'\n",
    "graph.render('vinos')\n",
    "\n",
    "# Obtengo la prediccion con el set de prueba definido anteriormente\n",
    "prediccion = t.predict(features_test)\n",
    "\n",
    "# Muestro prediccion vs original\n",
    "print(f'Predicción: \\t{prediccion}')\n",
    "print(f'Target: \\t{target_test}')\n",
    "print()\n",
    "\n",
    "# Veo qué tan acertado estuvo\n",
    "print(f'Precisión del modelo: {metrics.accuracy_score(target_test, prediccion)}')\n",
    "print()\n",
    "\n",
    "# Muestro un reporte de clasificación con diferentes métricas sobre cada feature \n",
    "print(f'Reporte de clasificación: \\n{metrics.classification_report(target_test, prediccion)}')\n"
   ]
  },
  {
   "source": [
    "![Vinos](vinos.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "***Observaciones:***\n",
    "- La primer solución obtenida posee una precisión del 94.4%.\n",
    "- Falló solo dos veces. \n",
    "- El modelo posee una profundidad de 5 niveles.\n",
    "- La hoja con mayor cantidad de sampleos posee 44, un valor algo eleveado teniendo en cuenta que hay 178 registros.\n",
    "- La hoja con menor cantidad de sampleos posee 1 y se encuentra en el último nivel.\n",
    "\n",
    "\n",
    "A continuación, se realizarán las siguientes pruebas para clasificar \"mejor\":\n",
    "- Limitar el mínimo de valores de samples en hojas a 20.\n",
    "- Limitar la cantidad de niveles a 3.\n",
    "- Árbol que clasifique aplicando Gini y no Entropía.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Predicción: \t[0 2 1 0 1 1 0 2 1 1 2 1 0 1 2 1 0 0 2 0 1 0 1 1 1 1 1 1 1 2 0 0 1 0 0 0]\nTarget: \t[0 2 1 0 1 1 0 2 1 1 2 2 0 1 2 1 0 0 1 0 1 0 0 1 1 1 1 1 1 2 0 0 1 0 0 0]\n\nPrecisión del modelo: 0.9166666666666666\n\nReporte de clasificación: \n              precision    recall  f1-score   support\n\n           0       1.00      0.93      0.96        14\n           1       0.88      0.94      0.91        16\n           2       0.83      0.83      0.83         6\n\n    accuracy                           0.92        36\n   macro avg       0.91      0.90      0.90        36\nweighted avg       0.92      0.92      0.92        36\n\n"
    }
   ],
   "source": [
    "# Instancio nuevamente el arbol por entropia pero cambio el sampleo en hojas\n",
    "t2 = tree.DecisionTreeClassifier(criterion='entropy', min_samples_leaf=20)\n",
    "\n",
    "# Lo entreno\n",
    "t2.fit(features_train, target_train)\n",
    "\n",
    "# Almaceno el modelo en formato DOT\n",
    "vinos_dot = tree.export_graphviz(t2\n",
    "                    , out_file=None\n",
    "                    , feature_names=vinos.feature_names\n",
    "                    , class_names=vinos.target_names\n",
    "                    , filled=True, rounded=True\n",
    "                    , special_characters=True)\n",
    "\n",
    "# Tambien lo guardo como PNG\n",
    "graph = graphviz.Source(vinos_dot)\n",
    "graph.format = 'png'\n",
    "graph.render('vinos_20')\n",
    "\n",
    "# Obtengo la prediccion con el set de prueba definido anteriormente\n",
    "prediccion_v2 = t2.predict(features_test)\n",
    "\n",
    "# Muestro prediccion vs original\n",
    "print(f'Predicción: \\t{prediccion_v2}')\n",
    "print(f'Target: \\t{target_test}')\n",
    "print()\n",
    "\n",
    "# Veo qué tan acertado estuvo\n",
    "print(f'Precisión del modelo: {metrics.accuracy_score(target_test, prediccion_v2)}')\n",
    "print()\n",
    "\n",
    "# Muestro un reporte de clasificación con diferentes métricas sobre cada feature \n",
    "print(f'Reporte de clasificación: \\n{metrics.classification_report(target_test, prediccion_v2)}')"
   ]
  },
  {
   "source": [
    "![Vinos](vinos_20.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Predicción: \t[0 2 1 0 1 1 0 2 1 1 2 2 0 1 2 1 0 0 2 0 1 0 1 1 1 1 1 1 1 2 0 0 1 0 0 0]\nTarget: \t[0 2 1 0 1 1 0 2 1 1 2 2 0 1 2 1 0 0 1 0 1 0 0 1 1 1 1 1 1 2 0 0 1 0 0 0]\n\nPrecisión del modelo: 0.9444444444444444\n\nReporte de clasificación: \n              precision    recall  f1-score   support\n\n           0       1.00      0.93      0.96        14\n           1       0.94      0.94      0.94        16\n           2       0.86      1.00      0.92         6\n\n    accuracy                           0.94        36\n   macro avg       0.93      0.96      0.94        36\nweighted avg       0.95      0.94      0.94        36\n\n"
    }
   ],
   "source": [
    "# Instancio nuevamente el arbol por entropia pero cambio la profundidad (de 0 a 2)\n",
    "t3 = tree.DecisionTreeClassifier(criterion='entropy', max_depth=2)\n",
    "\n",
    "# Lo entreno\n",
    "t3.fit(features_train, target_train)\n",
    "\n",
    "# Almaceno el modelo en formato DOT\n",
    "vinos_dot = tree.export_graphviz(t3\n",
    "                    , out_file=None\n",
    "                    , feature_names=vinos.feature_names\n",
    "                    , class_names=vinos.target_names\n",
    "                    , filled=True, rounded=True\n",
    "                    , special_characters=True)\n",
    "\n",
    "# Tambien lo guardo como PNG\n",
    "graph = graphviz.Source(vinos_dot)\n",
    "graph.format = 'png'\n",
    "graph.render('vinos_3_niveles')\n",
    "\n",
    "# Obtengo la prediccion con el set de prueba definido anteriormente\n",
    "prediccion_v3 = t3.predict(features_test)\n",
    "\n",
    "# Muestro prediccion vs original\n",
    "print(f'Predicción: \\t{prediccion_v3}')\n",
    "print(f'Target: \\t{target_test}')\n",
    "print()\n",
    "\n",
    "# Veo qué tan acertado estuvo\n",
    "print(f'Precisión del modelo: {metrics.accuracy_score(target_test, prediccion_v3)}')\n",
    "print()\n",
    "\n",
    "# Muestro un reporte de clasificación con diferentes métricas sobre cada feature \n",
    "print(f'Reporte de clasificación: \\n{metrics.classification_report(target_test, prediccion_v3)}')"
   ]
  },
  {
   "source": [
    "![Vinos](vinos_3_niveles.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Predicción: \t[0 2 1 0 1 1 0 2 1 1 2 2 0 1 2 1 0 0 1 0 0 0 0 1 1 1 1 1 1 2 0 0 1 0 0 0]\nTarget: \t[0 2 1 0 1 1 0 2 1 1 2 2 0 1 2 1 0 0 1 0 1 0 0 1 1 1 1 1 1 2 0 0 1 0 0 0]\n\nPrecisión del modelo: 0.9722222222222222\n\nReporte de clasificación: \n              precision    recall  f1-score   support\n\n           0       0.93      1.00      0.97        14\n           1       1.00      0.94      0.97        16\n           2       1.00      1.00      1.00         6\n\n    accuracy                           0.97        36\n   macro avg       0.98      0.98      0.98        36\nweighted avg       0.97      0.97      0.97        36\n\n"
    }
   ],
   "source": [
    "# Instancio nuevamente el arbol pero para que clasifique por Gini\n",
    "t4 = tree.DecisionTreeClassifier(criterion='gini')\n",
    "\n",
    "# Lo entreno\n",
    "t4.fit(features_train, target_train)\n",
    "\n",
    "# Almaceno el modelo en formato DOT\n",
    "vinos_dot = tree.export_graphviz(t4\n",
    "                    , out_file=None\n",
    "                    , feature_names=vinos.feature_names\n",
    "                    , class_names=vinos.target_names\n",
    "                    , filled=True, rounded=True\n",
    "                    , special_characters=True)\n",
    "\n",
    "# Tambien lo guardo como PNG\n",
    "graph = graphviz.Source(vinos_dot)\n",
    "graph.format = 'png'\n",
    "graph.render('vinos_gini')\n",
    "\n",
    "# Obtengo la prediccion con el set de prueba definido anteriormente\n",
    "prediccion_v4 = t4.predict(features_test)\n",
    "\n",
    "# Muestro prediccion vs original\n",
    "print(f'Predicción: \\t{prediccion_v4}')\n",
    "print(f'Target: \\t{target_test}')\n",
    "print()\n",
    "\n",
    "# Veo qué tan acertado estuvo\n",
    "print(f'Precisión del modelo: {metrics.accuracy_score(target_test, prediccion_v4)}')\n",
    "print()\n",
    "\n",
    "# Muestro un reporte de clasificación con diferentes métricas sobre cada feature \n",
    "print(f'Reporte de clasificación: \\n{metrics.classification_report(target_test, prediccion_v4)}')"
   ]
  },
  {
   "source": [
    "![Arbol](vinos_gini.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "***Observaciones:***\n",
    "- La versión 2, con un límite mínimo de 20 samples por hoja, tiene menos precisión en la predicción con respecto a la versión original: 91.6% vs 94.4% respectivamente.\n",
    "\n",
    "- La versión 3, con un límite de profundidad de 3 niveles, mantuvo la misma precisión que el modelo original pero se \"ahorró\" 2 niveles. Probablemente si se destinara un set de test mayor al 20% que solicita la consigna, la precisión decaiga.\n",
    "\n",
    "- La versión 4, que clasifica utilizando el Nivel de Pureza de un dato (Gini) y no la Ganancia de Información (Entropía), fué el que mayor precisión brindó: 97.2%.\n",
    "\n",
    "## Conclusiones:\n",
    "\n",
    "- Según los resultados de *este* dataset, la clasificación aplicando el método Gini fué la más precisa de las 4 exploradas, es decir, la \"mejor\".\n",
    "\n",
    "- Eso no significa que sea una regla general. Sino que, dado este dataset de vinos, dicho método es el que con mayor precisión predice."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}